{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from S3 Public Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import December Flights Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8651A</td>\n",
       "      <td>3689</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>14679</td>\n",
       "      <td>...</td>\n",
       "      <td>245.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N939WN</td>\n",
       "      <td>2600</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>14683</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7741C</td>\n",
       "      <td>2770</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>14683</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N550WN</td>\n",
       "      <td>6654</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>14747</td>\n",
       "      <td>...</td>\n",
       "      <td>275.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8319F</td>\n",
       "      <td>3402</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>14771</td>\n",
       "      <td>...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "0     12             8            7                WN   N8651A   \n",
       "1     12             8            7                WN   N939WN   \n",
       "2     12             8            7                WN   N7741C   \n",
       "3     12             8            7                WN   N550WN   \n",
       "4     12             8            7                WN   N8319F   \n",
       "\n",
       "   OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID ORIGIN ORIGIN_CITY_NAME  \\\n",
       "0               3689              15016    STL    St. Louis, MO   \n",
       "1               2600              15016    STL    St. Louis, MO   \n",
       "2               2770              15016    STL    St. Louis, MO   \n",
       "3               6654              15016    STL    St. Louis, MO   \n",
       "4               3402              15016    STL    St. Louis, MO   \n",
       "\n",
       "   DEST_AIRPORT_ID  ... CRS_ELAPSED_TIME ACTUAL_ELAPSED_TIME  DISTANCE  \\\n",
       "0            14679  ...            245.0               266.0    1557.0   \n",
       "1            14683  ...            145.0               125.0     786.0   \n",
       "2            14683  ...            140.0               131.0     786.0   \n",
       "3            14747  ...            275.0               256.0    1709.0   \n",
       "4            14771  ...            270.0               256.0    1735.0   \n",
       "\n",
       "   DISTANCE_GROUP  CARRIER_DELAY  WEATHER_DELAY NAS_DELAY  SECURITY_DELAY  \\\n",
       "0               7            0.0            0.0      18.0             0.0   \n",
       "1               4            NaN            NaN       NaN             NaN   \n",
       "2               4            NaN            NaN       NaN             NaN   \n",
       "3               7            NaN            NaN       NaN             NaN   \n",
       "4               7            NaN            NaN       NaN             NaN   \n",
       "\n",
       "   LATE_AIRCRAFT_DELAY  Unnamed: 32  \n",
       "0                  0.0          NaN  \n",
       "1                  NaN          NaN  \n",
       "2                  NaN          NaN  \n",
       "3                  NaN          NaN  \n",
       "4                  NaN          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using boto for s3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Bucket name\n",
    "BUCKET='ads-508'\n",
    "\n",
    "# file name\n",
    "KEY='ONTIME_REPORTING_12.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "dec_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "# read in data as pandas data frame\n",
    "Dec_flight = pd.read_csv(dec_response.get(\"Body\"))\n",
    "Dec_flight.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                       0\n",
       "DAY_OF_MONTH                0\n",
       "DAY_OF_WEEK                 0\n",
       "OP_UNIQUE_CARRIER           0\n",
       "TAIL_NUM                  457\n",
       "OP_CARRIER_FL_NUM           0\n",
       "ORIGIN_AIRPORT_ID           0\n",
       "ORIGIN                      0\n",
       "ORIGIN_CITY_NAME            0\n",
       "DEST_AIRPORT_ID             0\n",
       "DEST                        0\n",
       "DEST_CITY_NAME              0\n",
       "CRS_DEP_TIME                0\n",
       "DEP_TIME                 5510\n",
       "DEP_DELAY_NEW            5510\n",
       "DEP_DEL15                5510\n",
       "DEP_TIME_BLK                0\n",
       "CRS_ARR_TIME                0\n",
       "ARR_TIME                 6045\n",
       "ARR_DELAY_NEW            7151\n",
       "ARR_TIME_BLK                0\n",
       "CANCELLED                   0\n",
       "CANCELLATION_CODE      619970\n",
       "CRS_ELAPSED_TIME            0\n",
       "ACTUAL_ELAPSED_TIME      7151\n",
       "DISTANCE                    0\n",
       "DISTANCE_GROUP              0\n",
       "CARRIER_DELAY          498818\n",
       "WEATHER_DELAY          498818\n",
       "NAS_DELAY              498818\n",
       "SECURITY_DELAY         498818\n",
       "LATE_AIRCRAFT_DELAY    498818\n",
       "Unnamed: 32            625763\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec_flight.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with missing departure time and tail number.  \n",
    "Dec_flight.drop(Dec_flight.loc[Dec_flight['DEP_TIME'].isna()].index, axis=0, inplace=True) \n",
    "Dec_flight.drop(Dec_flight.loc[Dec_flight['ARR_TIME'].isna()].index, axis=0, inplace=True) \n",
    " \n",
    "# Drop cancelled flights \n",
    "Dec_flight.drop(Dec_flight[Dec_flight['CANCELLED'] == 1].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                       0\n",
       "DAY_OF_MONTH                0\n",
       "DAY_OF_WEEK                 0\n",
       "OP_UNIQUE_CARRIER           0\n",
       "TAIL_NUM                    0\n",
       "OP_CARRIER_FL_NUM           0\n",
       "ORIGIN_AIRPORT_ID           0\n",
       "ORIGIN                      0\n",
       "ORIGIN_CITY_NAME            0\n",
       "DEST_AIRPORT_ID             0\n",
       "DEST                        0\n",
       "DEST_CITY_NAME              0\n",
       "CRS_DEP_TIME                0\n",
       "DEP_TIME                    0\n",
       "DEP_DELAY_NEW               0\n",
       "DEP_DEL15                   0\n",
       "DEP_TIME_BLK                0\n",
       "CRS_ARR_TIME                0\n",
       "ARR_TIME                    0\n",
       "ARR_DELAY_NEW            1106\n",
       "ARR_TIME_BLK                0\n",
       "CANCELLED                   0\n",
       "CANCELLATION_CODE      619718\n",
       "CRS_ELAPSED_TIME            0\n",
       "ACTUAL_ELAPSED_TIME      1106\n",
       "DISTANCE                    0\n",
       "DISTANCE_GROUP              0\n",
       "CARRIER_DELAY          492773\n",
       "WEATHER_DELAY          492773\n",
       "NAS_DELAY              492773\n",
       "SECURITY_DELAY         492773\n",
       "LATE_AIRCRAFT_DELAY    492773\n",
       "Unnamed: 32            619718\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec_flight.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1106.000000\n",
       "mean      -22.830922\n",
       "std       786.554676\n",
       "min     -2305.000000\n",
       "25%       136.000000\n",
       "50%       258.000000\n",
       "75%       375.000000\n",
       "max      1758.000000\n",
       "Name: ARR_DELAY_NEW, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate the observations with missing Arrival delay information \n",
    "MISSING_ARR_DELAY = Dec_flight[Dec_flight['ARR_DELAY_NEW'].isna()] \n",
    " \n",
    "# Manually calculate the arrival delay value and check if that solves the missing arrival delay information \n",
    "MISSING_ARR_DELAY['ARR_DELAY_NEW'] = MISSING_ARR_DELAY['ARR_TIME'] - MISSING_ARR_DELAY['CRS_ARR_TIME'] \n",
    " \n",
    "# Review the descriptive statistics for the new calculated values to ensure no negatives or errors \n",
    "MISSING_ARR_DELAY['ARR_DELAY_NEW'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Aircraft Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa0 in position 6: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 6: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d328a2a206c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Import aircraft information - tail numbers, manufacture year, and capacity information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0maircraft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mair_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Body\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0maircraft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 6: invalid start byte"
     ]
    }
   ],
   "source": [
    "# file name\n",
    "KEY= 'B43_AIRCRAFT_INVENTORY.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "air_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "# Import aircraft information - tail numbers, manufacture year, and capacity information\n",
    "aircraft = pd.read_csv(air_response.get(\"Body\"), encoding='latin1', engine = 'python')\n",
    "aircraft\n",
    "\n",
    "# Drop Duplicates to retain a dictionary \n",
    "aircraft.drop_duplicates(subset='TAIL_NUM', inplace=True) \n",
    "aircraft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MANUFACTURE_YEAR</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>NUMBER_OF_SEATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1944</td>\n",
       "      <td>N54514</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1945</td>\n",
       "      <td>N1651M</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953</td>\n",
       "      <td>N100CE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>N141FL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953</td>\n",
       "      <td>N151FL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>2019</td>\n",
       "      <td>N14011</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>2019</td>\n",
       "      <td>N16008</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7380</th>\n",
       "      <td>2019</td>\n",
       "      <td>N16009</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>2019</td>\n",
       "      <td>N2250U</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7382</th>\n",
       "      <td>2019</td>\n",
       "      <td>N2749U</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7383 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MANUFACTURE_YEAR TAIL_NUM  NUMBER_OF_SEATS\n",
       "0                 1944   N54514              0.0\n",
       "1                 1945   N1651M              0.0\n",
       "2                 1953   N100CE              0.0\n",
       "3                 1953   N141FL              0.0\n",
       "4                 1953   N151FL              0.0\n",
       "...                ...      ...              ...\n",
       "7378              2019   N14011            337.0\n",
       "7379              2019   N16008            337.0\n",
       "7380              2019   N16009            337.0\n",
       "7381              2019   N2250U            276.0\n",
       "7382              2019   N2749U            276.0\n",
       "\n",
       "[7383 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../src/data/raw_data/B43_AIRCRAFT_INVENTORY.csv\", engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Decode Carrier Names Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE_ID</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>CARRIER_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21754</td>\n",
       "      <td>2PQ</td>\n",
       "      <td>21 Air LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20342</td>\n",
       "      <td>Q5</td>\n",
       "      <td>40-Mile Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20342</td>\n",
       "      <td>WRB</td>\n",
       "      <td>40-Mile Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19627</td>\n",
       "      <td>CIQ</td>\n",
       "      <td>A/S Conair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19072</td>\n",
       "      <td>AAE</td>\n",
       "      <td>AAA Airlines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIRLINE_ID OP_UNIQUE_CARRIER  CARRIER_NAME\n",
       "0       21754               2PQ    21 Air LLC\n",
       "1       20342                Q5   40-Mile Air\n",
       "2       20342               WRB   40-Mile Air\n",
       "3       19627               CIQ    A/S Conair\n",
       "4       19072               AAE  AAA Airlines"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "KEY= 'CARRIER_DECODE.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "decode_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "# Create dictionary for consistent carrier names using OP_Unique_carrier and Airline_ID \n",
    "names = pd.read_csv(decode_response.get(\"Body\"))\n",
    " \n",
    "# Drop Duplicates to retain a dictionary \n",
    "names.drop_duplicates(subset='OP_UNIQUE_CARRIER', inplace=True) \n",
    "names = names.reset_index(drop=True)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Employee Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>PILOTS_COPILOTS</th>\n",
       "      <th>PASSENGER_HANDLING</th>\n",
       "      <th>PASS_GEN_SVC_ADMIN</th>\n",
       "      <th>MAINTENANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>8586</td>\n",
       "      <td>8586</td>\n",
       "      <td>15502</td>\n",
       "      <td>9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>2893</td>\n",
       "      <td>1062</td>\n",
       "      <td>5737</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B6</td>\n",
       "      <td>2840</td>\n",
       "      <td>4905</td>\n",
       "      <td>3888</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>9293</td>\n",
       "      <td>15331</td>\n",
       "      <td>15809</td>\n",
       "      <td>6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F9</td>\n",
       "      <td>1473</td>\n",
       "      <td>2496</td>\n",
       "      <td>154</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G4</td>\n",
       "      <td>953</td>\n",
       "      <td>200</td>\n",
       "      <td>1626</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HA</td>\n",
       "      <td>586</td>\n",
       "      <td>893</td>\n",
       "      <td>1466</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MQ</td>\n",
       "      <td>2109</td>\n",
       "      <td>4923</td>\n",
       "      <td>1510</td>\n",
       "      <td>1565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NK</td>\n",
       "      <td>2126</td>\n",
       "      <td>264</td>\n",
       "      <td>3592</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OO</td>\n",
       "      <td>5175</td>\n",
       "      <td>1407</td>\n",
       "      <td>4076</td>\n",
       "      <td>2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QX</td>\n",
       "      <td>824</td>\n",
       "      <td>2097</td>\n",
       "      <td>685</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SY</td>\n",
       "      <td>303</td>\n",
       "      <td>10</td>\n",
       "      <td>534</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UA</td>\n",
       "      <td>7637</td>\n",
       "      <td>16888</td>\n",
       "      <td>15237</td>\n",
       "      <td>4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WN</td>\n",
       "      <td>8989</td>\n",
       "      <td>9668</td>\n",
       "      <td>15475</td>\n",
       "      <td>2482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X9</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>YX</td>\n",
       "      <td>2444</td>\n",
       "      <td>23</td>\n",
       "      <td>2273</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OP_UNIQUE_CARRIER  PILOTS_COPILOTS  PASSENGER_HANDLING  PASS_GEN_SVC_ADMIN  \\\n",
       "0                 AA             8586                8586               15502   \n",
       "1                 AS             2893                1062                5737   \n",
       "2                 B6             2840                4905                3888   \n",
       "3                 DL             9293               15331               15809   \n",
       "4                 F9             1473                2496                 154   \n",
       "5                 G4              953                 200                1626   \n",
       "6                 HA              586                 893                1466   \n",
       "7                 MQ             2109                4923                1510   \n",
       "8                 NK             2126                 264                3592   \n",
       "9                 OO             5175                1407                4076   \n",
       "10                QX              824                2097                 685   \n",
       "11                SY              303                  10                 534   \n",
       "12                UA             7637               16888               15237   \n",
       "13                WN             8989                9668               15475   \n",
       "14                X9               31                   2                  33   \n",
       "15                YX             2444                  23                2273   \n",
       "\n",
       "    MAINTENANCE  \n",
       "0          9677  \n",
       "1           898  \n",
       "2           726  \n",
       "3          6122  \n",
       "4           237  \n",
       "5           420  \n",
       "6           419  \n",
       "7          1565  \n",
       "8           395  \n",
       "9          2145  \n",
       "10          261  \n",
       "11          149  \n",
       "12         4991  \n",
       "13         2482  \n",
       "14           20  \n",
       "15          787  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "KEY= 'P10_EMPLOYEES.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "emp_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "#Import Employee information \n",
    "employees = pd.read_csv(emp_response.get(\"Body\"))\n",
    "\n",
    "# Combine Carrier information for different entities and retain entitiy (only domestic), passenger handling (flight attendant), pass_gen_svc_admin (ground service), pilot_copilots and maintanence \n",
    "employees = employees[['OP_UNIQUE_CARRIER', 'ENTITY', 'PILOTS_COPILOTS', 'PASSENGER_HANDLING', 'PASS_GEN_SVC_ADMIN', 'MAINTENANCE']] \n",
    "\n",
    "# Drop on domestic entities \n",
    "employees.drop(employees[employees['ENTITY'] != 'D'].index, inplace = True) \n",
    " \n",
    "# Combine any remaining duplicates \n",
    "employees = employees.groupby('OP_UNIQUE_CARRIER').sum().reset_index() \n",
    " \n",
    "# Drop Parcel carriers (airlines with no flight attendants) \n",
    "employees.drop(employees[employees['PASSENGER_HANDLING'] == 0].index, inplace = True) \n",
    "employees = employees.reset_index(drop=True)\n",
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Airport Weather Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PGTM</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PSUN</th>\n",
       "      <th>SN32</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>...</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT07</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT10</th>\n",
       "      <th>WT18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00013874</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>16.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00013904</td>\n",
       "      <td>AUSTIN BERGSTROM INTERNATIONAL AIRPORT, TX US</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>10.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00093721</td>\n",
       "      <td>BALTIMORE WASHINGTON INTERNATIONAL AIRPORT, MD US</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00013881</td>\n",
       "      <td>CHARLOTTE DOUGLAS AIRPORT, NC US</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>10.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00093812</td>\n",
       "      <td>CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>11.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                                               NAME       DATE  \\\n",
       "0  USW00013874  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  12/1/2019   \n",
       "1  USW00013904      AUSTIN BERGSTROM INTERNATIONAL AIRPORT, TX US  12/1/2019   \n",
       "2  USW00093721  BALTIMORE WASHINGTON INTERNATIONAL AIRPORT, MD US  12/1/2019   \n",
       "3  USW00013881                   CHARLOTTE DOUGLAS AIRPORT, NC US  12/1/2019   \n",
       "4  USW00093812   CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US  12/1/2019   \n",
       "\n",
       "    AWND  PGTM  PRCP  PSUN  SN32  SNOW  SNWD  ...  WT02  WT03  WT04  WT05  \\\n",
       "0  16.11   NaN  0.04   0.0   0.0  64.0  67.0  ...   NaN   NaN   NaN   NaN   \n",
       "1  10.29   NaN  0.00   0.0   0.0  62.0  66.0  ...   NaN   NaN   NaN   NaN   \n",
       "2   8.05   NaN  0.62   0.0   0.0  41.0  45.0  ...   NaN   1.0   NaN   NaN   \n",
       "3  10.29   NaN  0.60   0.0   0.0  56.0  68.0  ...   NaN   NaN   NaN   NaN   \n",
       "4  11.41   NaN  0.09   NaN   NaN   NaN  60.0  ...   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   WT06  WT07  WT08  WT09  WT10  WT18  \n",
       "0   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "KEY= 'airport_weather_dec_2019.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "weather_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "#Import weather airport information \n",
    "weather_report = pd.read_csv(weather_response.get(\"Body\"))\n",
    "weather_report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Airport City Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DISPLAY_AIRPORT_NAME</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10257</td>\n",
       "      <td>Albany International</td>\n",
       "      <td>Albany, NY</td>\n",
       "      <td>ALBANY INTERNATIONAL AIRPORT, NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10140</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>ALBUQUERQUE INTERNATIONAL AIRPORT, NM US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10299</td>\n",
       "      <td>Anchorage International</td>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>ANCHORAGE TED STEVENS INTERNATIONAL AIRPORT, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10397</td>\n",
       "      <td>Atlanta Municipal</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORIGIN_AIRPORT_ID               DISPLAY_AIRPORT_NAME ORIGIN_CITY_NAME  \\\n",
       "0              12992                        Adams Field  Little Rock, AR   \n",
       "1              10257               Albany International       Albany, NY   \n",
       "2              10140  Albuquerque International Sunport  Albuquerque, NM   \n",
       "3              10299            Anchorage International    Anchorage, AK   \n",
       "4              10397                  Atlanta Municipal      Atlanta, GA   \n",
       "\n",
       "                                                NAME  \n",
       "0                   NORTH LITTLE ROCK AIRPORT, AR US  \n",
       "1                ALBANY INTERNATIONAL AIRPORT, NY US  \n",
       "2           ALBUQUERQUE INTERNATIONAL AIRPORT, NM US  \n",
       "3  ANCHORAGE TED STEVENS INTERNATIONAL AIRPORT, A...  \n",
       "4  ATLANTA HARTSFIELD JACKSON INTERNATIONAL AIRPO...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file name\n",
    "KEY= 'airports_list.csv'\n",
    "\n",
    "# Get object in bucket\n",
    "cities_response = s3_client.get_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "# Import city and airport name dictionary\n",
    "cities = pd.read_csv(cities_response.get(\"Body\"))\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DISPLAY_AIRPORT_NAME</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PGTM</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PSUN</th>\n",
       "      <th>...</th>\n",
       "      <th>WT02</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT07</th>\n",
       "      <th>WT08</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT10</th>\n",
       "      <th>WT18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "      <td>USW00003952</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>10.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "      <td>USW00003952</td>\n",
       "      <td>12/2/2019</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "      <td>USW00003952</td>\n",
       "      <td>12/3/2019</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "      <td>USW00003952</td>\n",
       "      <td>12/4/2019</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12992</td>\n",
       "      <td>Adams Field</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>NORTH LITTLE ROCK AIRPORT, AR US</td>\n",
       "      <td>USW00003952</td>\n",
       "      <td>12/5/2019</td>\n",
       "      <td>4.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORIGIN_AIRPORT_ID DISPLAY_AIRPORT_NAME ORIGIN_CITY_NAME  \\\n",
       "0              12992          Adams Field  Little Rock, AR   \n",
       "1              12992          Adams Field  Little Rock, AR   \n",
       "2              12992          Adams Field  Little Rock, AR   \n",
       "3              12992          Adams Field  Little Rock, AR   \n",
       "4              12992          Adams Field  Little Rock, AR   \n",
       "\n",
       "                               NAME      STATION       DATE   AWND  PGTM  \\\n",
       "0  NORTH LITTLE ROCK AIRPORT, AR US  USW00003952  12/1/2019  10.07   NaN   \n",
       "1  NORTH LITTLE ROCK AIRPORT, AR US  USW00003952  12/2/2019   4.03   NaN   \n",
       "2  NORTH LITTLE ROCK AIRPORT, AR US  USW00003952  12/3/2019   4.03   NaN   \n",
       "3  NORTH LITTLE ROCK AIRPORT, AR US  USW00003952  12/4/2019   2.91   NaN   \n",
       "4  NORTH LITTLE ROCK AIRPORT, AR US  USW00003952  12/5/2019   4.92   NaN   \n",
       "\n",
       "   PRCP  PSUN  ...  WT02  WT03  WT04  WT05  WT06  WT07  WT08  WT09  WT10  WT18  \n",
       "0  0.00   0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1  0.00   0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2  0.00   0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3  0.00   0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4  0.01   0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge weather report and cities for future merging \n",
    "weather_merge = pd.merge(cities, weather_report, how='left', on='NAME') \n",
    "weather_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                   1\n",
       "PRCP                   1\n",
       "SNOW                 621\n",
       "SNWD                   2\n",
       "TMAX                   9\n",
       "AWND                   1\n",
       "ORIGIN_AIRPORT_ID      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit scope of weather metrics (date, precipitation, snow, max temp, and wind) \n",
    "weather = weather_merge[['DATE', 'PRCP', 'SNOW', 'SNWD','TMAX', 'AWND', 'ORIGIN_AIRPORT_ID']]\n",
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:8767: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Replace missing snow values with 0 for days with 0 preciptation \n",
    "weather.SNOW.where((~weather.SNOW.isna()) & (weather.PRCP != '0.00'), \n",
    "                     '0.00', inplace=True) \n",
    " \n",
    "# Replace missing snow depth (SNWD) values with 0 for days with no snow \n",
    "weather.SNWD.where((~weather.SNWD.isna()) & (weather.SNOW != '0.00'), \n",
    "                     '0.00', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                 1\n",
       "PRCP                 1\n",
       "SNOW                 0\n",
       "SNWD                 0\n",
       "TMAX                 9\n",
       "AWND                 1\n",
       "ORIGIN_AIRPORT_ID    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>AWND</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.07</td>\n",
       "      <td>12992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>12992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>12992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>12992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>12992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>10713</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>10713</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>140.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>10713</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>10713</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.29</td>\n",
       "      <td>10713</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2977 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE  PRCP  SNOW  SNWD   TMAX   AWND  ORIGIN_AIRPORT_ID  MONTH  \\\n",
       "0    2019-12-01  0.00  0.00  0.00  270.0  10.07              12992   12.0   \n",
       "1    2019-12-02  0.00  0.00  0.00   40.0   4.03              12992   12.0   \n",
       "2    2019-12-03  0.00  0.00  0.00  240.0   4.03              12992   12.0   \n",
       "3    2019-12-04  0.00  0.00  0.00  320.0   2.91              12992   12.0   \n",
       "4    2019-12-05  0.01  0.00  0.00  150.0   4.92              12992   12.0   \n",
       "...         ...   ...   ...   ...    ...    ...                ...    ...   \n",
       "2972 2019-12-27  0.00    32    35  320.0   5.82              10713   12.0   \n",
       "2973 2019-12-28  0.00    29    39  300.0   2.24              10713   12.0   \n",
       "2974 2019-12-29  0.04    31    32  140.0   6.26              10713   12.0   \n",
       "2975 2019-12-30  0.00    31    34  130.0   2.46              10713   12.0   \n",
       "2976 2019-12-31  0.01    34    40  120.0  10.29              10713   12.0   \n",
       "\n",
       "      DAY_OF_MONTH  \n",
       "0              1.0  \n",
       "1              2.0  \n",
       "2              3.0  \n",
       "3              4.0  \n",
       "4              5.0  \n",
       "...            ...  \n",
       "2972          27.0  \n",
       "2973          28.0  \n",
       "2974          29.0  \n",
       "2975          30.0  \n",
       "2976          31.0  \n",
       "\n",
       "[2977 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change date format to match flight data (Month & Day_of_Month) \n",
    "weather['DATE'] = pd.to_datetime(weather['DATE']) \n",
    "weather['MONTH'] = pd.DatetimeIndex(weather['DATE']).month \n",
    "weather['DAY_OF_MONTH'] = pd.DatetimeIndex(weather['DATE']).day \n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TAIL_NUM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ddb981021282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge aircraft information into flight data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDec_flight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDec_flight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maircraft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TAIL_NUM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TAIL_NUM'"
     ]
    }
   ],
   "source": [
    "# Merge aircraft information into flight data file \n",
    "Dec_flight = pd.merge(Dec_flight, aircraft, how=\"left\", on='TAIL_NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge names and flight data for consistent airline names \n",
    "Dec_flight = pd.merge(Dec_flight, names, how='left', on=['OP_UNIQUE_CARRIER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Employee\n",
    "Dec_flight = pd.merge(Dec_flight, employees, how='left', on=['OP_UNIQUE_CARRIER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dec_flight.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rop airlines with missing employee data \n",
    "Dec_flight.drop(Dec_flight.loc[Dec_flight['PASSENGER_HANDLING'].isna()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Semi_final = Dec_flight.reset_index(drop=True)\n",
    "Semi_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Redundant feature \n",
    "Final = Semi_final.drop(columns=['ORIGIN_AIRPORT_ID', 'ORIGIN_CITY_NAME', 'DEST_AIRPORT_ID', 'DEST_CITY_NAME'])\n",
    " \n",
    "# Dropping extensive missing features \n",
    "Final = Final.drop(columns=['CARRIER_DELAY', 'WEATHER_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'NAS_DELAY', 'CANCELLATION_CODE', 'Unnamed: 32', 'CANCELLED']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
